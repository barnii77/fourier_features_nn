{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9251dbeeff944d568949047c005828e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52a87c12157f40f0bb4454dd6cb54a99",
              "IPY_MODEL_74fa73e249a6437a92af6157de21e3ca"
            ],
            "layout": "IPY_MODEL_7737207cb45f42439bbc105815421bff"
          }
        },
        "52a87c12157f40f0bb4454dd6cb54a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66e7379d4d2e46ae9bcbac51dec080b1",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6681e181104d22abe55ca73bba1c43",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "74fa73e249a6437a92af6157de21e3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e92733dacf24b3da4c09ceaca1ae329",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2b8f79a46534fb59a55860933ebce8a",
            "value": 0.9619412001610954
          }
        },
        "7737207cb45f42439bbc105815421bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e7379d4d2e46ae9bcbac51dec080b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6681e181104d22abe55ca73bba1c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e92733dacf24b3da4c09ceaca1ae329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b8f79a46534fb59a55860933ebce8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install all libraries that are not pre-installed in colab\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WLSsZCZHmLg",
        "outputId": "6125108b-d93b-45da-a5aa-475bcc67877d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=30ba36dbb7af2cbf0abda556d69843fce591e01a1d6bea8a1f3a8757ffe61449\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if all files have been uploaded\n",
        "import os\n",
        "content = os.listdir()\n",
        "assert \"views\" in content\n",
        "assert \"hyperparameters.json\" in content"
      ],
      "metadata": {
        "id": "N3VZgk1Hh8lo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QFeCIdpRF40d"
      },
      "outputs": [],
      "source": [
        "raise Exception(\"Deprecated cell. You should not need to use this.\")\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "with open('view_info.json', 'r') as f:\n",
        "    view_data = json.load(f)\n",
        "data_path = '/'.join(view_data[0]['image'].split('/')[:-1])\n",
        "if not os.path.exists(data_path):\n",
        "    for i in range(len(view_data)):\n",
        "      view_data[i]['image'] = view_data[i]['image'].split('/')[-1]\n",
        "    with open('view_info.json', 'w') as f:\n",
        "      json.dump(view_data, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main training/resume/eval loop. wandb logging.\n",
        "import json\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "\n",
        "class FourierLayer(nn.Module):\n",
        "    def __init__(self, n_fourier_features: int, freq_spacing: str = 'logarithmic', fan_in: int = None, no_grad: bool = True):\n",
        "        super().__init__()\n",
        "        self.nff = n_fourier_features\n",
        "        self.fan_in = fan_in\n",
        "        if fan_in is not None:\n",
        "            self.out_dim = 2 * fan_in * self.nff\n",
        "        else:\n",
        "            self.out_dim = None\n",
        "        self.freq_spacing = freq_spacing\n",
        "        self.no_grad = no_grad\n",
        "\n",
        "    def forward_fn(self, x):\n",
        "        x = x.view(x.shape + (1,))\n",
        "        if self.freq_spacing == 'logarithmic':\n",
        "            feature_mul = 2 ** torch.arange(0, self.nff, device=x.device)\n",
        "        elif self.freq_spacing == 'linear':\n",
        "            feature_mul = torch.arange(1, self.nff + 1, device=x.device)\n",
        "        else:\n",
        "            raise Exception(f'Unknown frequency spacing paradigm: {self.freq_spacing}')\n",
        "        sines = torch.sin(x * feature_mul)\n",
        "        cosines = torch.cos(x * feature_mul)\n",
        "        del feature_mul\n",
        "        # sines.shape = cosines.shape\n",
        "        out = (torch.concat([\n",
        "            sines.view(sines.shape + (1,)),\n",
        "            cosines.view(cosines.shape + (1,))\n",
        "        ],\n",
        "            dim=-1)\n",
        "               .flatten(-3, -1)\n",
        "               )\n",
        "        del sines, cosines\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert not (self.no_grad and x.requires_grad), \"FourierLayer is set to no_grad = True, but input requires grad.\"\n",
        "        if self.no_grad:\n",
        "            with torch.no_grad():\n",
        "                return self.forward_fn(x).detach()\n",
        "        return self.forward_fn(x)\n",
        "\n",
        "\n",
        "def factorize_with_smallest_difference(n):\n",
        "    factors = []\n",
        "\n",
        "    for i in range(1, int(n ** 0.5) + 1):\n",
        "        if n % i == 0:\n",
        "            factors.append((i, n // i))\n",
        "\n",
        "    best_factors = min(factors, key=lambda pair: abs(pair[0] - pair[1]))\n",
        "\n",
        "    return best_factors\n",
        "\n",
        "\n",
        "\"\"\"parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--path', type=str, default='views', help=\"path to .json file containing the image info\")\n",
        "parser.add_argument('--train', action='store_true', help=\"train a new model\")\n",
        "parser.add_argument('--eval', action='store_true', help=\"evaluate currently saved model\")\n",
        "parser.add_argument('--resume', action='store_true', help=\"continue training currently saved model\")\n",
        "parser.add_argument('--cuda', action='store_true', help=\"use cuda for training\")\n",
        "parser.add_argument('--verbose', action='store_true', help=\"print epoch to console\")\n",
        "parser.add_argument('--wandb', type=str, default=None, help=\"wandb project to log this run to\")\n",
        "args = parser.parse_args()\"\"\"  # because colab does not support this (or I am too dumb to find it)\n",
        "args = argparse.Namespace(\n",
        "    path='views',\n",
        "    train=False,\n",
        "    eval=False,\n",
        "    resume=True,\n",
        "    cuda=True,\n",
        "    verbose=True,\n",
        "    wandb=\"arxiv_2006.10739\"\n",
        ")\n",
        "\n",
        "assert args.train or args.eval or args.resume, \"You must provide one of --train, --eval or --resume\"\n",
        "assert sum(\n",
        "    map(int, [args.train, args.eval, args.resume])) == 1, \"You must provide only one of --train, --eval or --resume\"\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# load hyperparams from file\n",
        "with open('hyperparameters.json') as f:\n",
        "    hyperparams_dict = json.load(f)\n",
        "    hyperparams = argparse.Namespace(**hyperparams_dict)\n",
        "\n",
        "if args.wandb is not None:\n",
        "    if args.train or args.resume:\n",
        "        wandb.init(\n",
        "            project=args.wandb,\n",
        "            config=hyperparams_dict\n",
        "        )\n",
        "    else:\n",
        "        wandb.init(\n",
        "            project=args.wandb\n",
        "        )\n",
        "\n",
        "# load images\n",
        "pics, cam_pos, cam_rot = [], [], []\n",
        "json_fn = None\n",
        "for fn in os.listdir(f\"{args.path}/\"):\n",
        "    if fn.endswith('.json'):\n",
        "        assert json_fn is None, \"More than one json file in data directory. Remove all but the necessary one.\"\n",
        "        json_fn = fn\n",
        "\n",
        "assert json_fn is not None, \"Could not find a json file containing dataset info\"\n",
        "\n",
        "with open(f\"{args.path}/{json_fn}\") as f:\n",
        "    data_json = json.load(f)\n",
        "\n",
        "for x in data_json:\n",
        "    pic = Image.open(x[\"image\"]).convert('RGB')\n",
        "    pic = transform(pic).permute((2, 1, 0)).unsqueeze(0)\n",
        "    pics.append(pic)\n",
        "    pos = torch.tensor(list(map(float, x[\"position\"].split(', '))))\n",
        "    cam_pos.append(pos)\n",
        "    rot = torch.tensor(list(map(float, x[\"rotation\"].split(', '))))\n",
        "    cam_rot.append(rot)\n",
        "\n",
        "assert all([i.shape == j.shape for i, j in zip(pics, pics[1:])]), \"Not all images have the same shape.\"\n",
        "pics = torch.concat(pics)\n",
        "cam_pos = torch.stack(cam_pos)\n",
        "cam_rot = torch.stack(cam_rot)\n",
        "\n",
        "if hyperparams.batch_size == -1:\n",
        "    hyperparams.batch_size = pics.shape[0]\n",
        "assert pics.shape[\n",
        "           0] % hyperparams.batch_size == 0, f\"Cannot divide {pics.shape[0]} images evenly into {hyperparams.batch_size} groups\"\n",
        "assert pics.shape[\n",
        "           1] % hyperparams.n_image_splits == 0, f\"Cannot horizontally divide images of horizontal size {pics.shape[1]} evenly into {hyperparams.n_image_splits} equal segments\"\n",
        "\n",
        "# define model input\n",
        "# pure pixel position input + reshape\n",
        "'''\n",
        "model_in = torch.concat(\n",
        "    [torch.arange(pics.shape[1]).unsqueeze(-1).repeat_interleave(pics.shape[2], dim=1).unsqueeze(-1),\n",
        "     torch.arange(pics.shape[2]).unsqueeze(0).repeat_interleave(pics.shape[1], dim=0).unsqueeze(-1)],\n",
        "    dim=-1) / torch.tensor(list(pics.shape[1:-1])) * 2 - 1\n",
        "\n",
        "Does the same thing (but worse) as:\n",
        "'''\n",
        "model_in = torch.stack(\n",
        "    [\n",
        "        torch.linspace(-1, 1, pics.shape[1]).unsqueeze(-1).repeat_interleave(pics.shape[2], dim=1),\n",
        "        torch.linspace(-1, 1, pics.shape[2]).unsqueeze(0).repeat_interleave(pics.shape[1], dim=0)\n",
        "    ],\n",
        "    dim=-1\n",
        ")\n",
        "model_in = model_in.unsqueeze(0).repeat_interleave(pics.shape[0], dim=0)\n",
        "# reshape camera position and rotation\n",
        "cam_pos = (cam_pos.view((cam_pos.shape[0], 1, 1, cam_pos.shape[1]))\n",
        "           .repeat_interleave(model_in.shape[1], dim=1)\n",
        "           .repeat_interleave(model_in.shape[2], dim=2))\n",
        "cam_rot = (cam_rot.view((cam_rot.shape[0], 1, 1, cam_rot.shape[1]))\n",
        "           .repeat_interleave(model_in.shape[1], dim=1)\n",
        "           .repeat_interleave(model_in.shape[2], dim=2))\n",
        "# concat\n",
        "model_in = torch.concat([cam_pos, cam_rot, model_in], dim=-1)\n",
        "\n",
        "# split model_in into pieces because it requires 600GiB GPU RAM otherwise D:\n",
        "X = []\n",
        "Y = []\n",
        "x_batch_splits = model_in.split(hyperparams.batch_size)\n",
        "y_batch_splits = pics.split(hyperparams.batch_size)\n",
        "\n",
        "for x_batch_split, y_batch_split in zip(x_batch_splits, y_batch_splits):\n",
        "    X.extend(x_batch_split.split(x_batch_split.shape[1] // hyperparams.n_image_splits, dim=1))\n",
        "    Y.extend(y_batch_split.split(y_batch_split.shape[1] // hyperparams.n_image_splits, dim=1))\n",
        "    del x_batch_split, y_batch_split\n",
        "\n",
        "# define the model\n",
        "if args.train:\n",
        "    fourier_layer = FourierLayer(\n",
        "        hyperparams.n_fourier_features,\n",
        "        hyperparams.frequency_spacing,\n",
        "        fan_in=model_in.shape[-1]\n",
        "    )\n",
        "    model = nn.Sequential(\n",
        "        fourier_layer,\n",
        "        nn.Linear(fourier_layer.out_dim, hyperparams.n_hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hyperparams.n_hidden, hyperparams.n_hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hyperparams.n_hidden, 3),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "else:\n",
        "    model = torch.load('model.ckpt')\n",
        "\n",
        "# define the optimizer\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=0)\n",
        "pred = None\n",
        "\n",
        "# move to gpu\n",
        "if args.cuda:\n",
        "    if torch.cuda.is_available():\n",
        "        # model_in = model_in.to('cuda')  not used anymore!!!\n",
        "        for i, x in enumerate(X):\n",
        "            X[i] = x.to('cuda')\n",
        "        for i, y in enumerate(Y):\n",
        "            Y[i] = y.to('cuda')\n",
        "        model = model.to('cuda')\n",
        "        # pics = pics.to('cuda')  not used anymore!!!\n",
        "        print('Moved parameters/IO to cuda')\n",
        "    else:\n",
        "        raise Exception('Cuda not available -> Failed to move parameters/IO to cuda')\n",
        "\n",
        "# delete unnecessary variables for gpu memory\n",
        "del transform, pics, cam_pos, cam_rot, model_in, x_batch_splits, y_batch_splits#, parser\n",
        "\n",
        "losses = []\n",
        "n_epochs = 0\n",
        "last_checkpoint_epoch_group_idx = 0\n",
        "\n",
        "# main training loop\n",
        "if args.train or args.resume:\n",
        "    print(\"Starting/resuming training...\")\n",
        "    for epoch_group_idx, lr_with_epochs in enumerate(hyperparams.learning_rates):\n",
        "        losses.append([])\n",
        "        for i in range(len(optim.param_groups)):\n",
        "            optim.param_groups[i]['lr'] = lr_with_epochs['lr']\n",
        "        for e in range(lr_with_epochs['epochs']):\n",
        "            losses[-1].append([])\n",
        "            for i, x, y in zip(range(len(X)), X, Y):\n",
        "                pred = (model(x) + 1) / 2\n",
        "                L = F.mse_loss(pred, y)\n",
        "                optim.zero_grad()\n",
        "                L.backward()\n",
        "                optim.step()\n",
        "                losses[-1][-1].append(L.item())\n",
        "            if args.wandb is not None:\n",
        "                wandb.log({f\"{'train' if args.train else 'resume'}/loss\": sum(losses[-1][-1]) / len(losses[-1][-1]), f\"{'train' if args.train else 'resume'}/lr\": lr_with_epochs['lr']})\n",
        "            if args.verbose:\n",
        "                print(f'Epoch {n_epochs}   Loss {sum(losses[-1][-1]) / len(losses[-1][-1])}')\n",
        "            n_epochs += 1\n",
        "        if lr_with_epochs['checkpoint'] and sum(losses[-1][-1]) <= sum(losses[last_checkpoint_epoch_group_idx][-1]):  # want to checkpoint and loss is better than at the end of last checkpointed epoch group (an epoch group is a group of epochs with shared lr)\n",
        "            last_checkpoint_epoch_group_idx = epoch_group_idx\n",
        "            torch.save(model, 'model.ckpt')\n",
        "            print(\"Saved the model to model.ckpt\")\n",
        "else:\n",
        "    print(\"Starting evaluation...\")\n",
        "    pred = []\n",
        "    for i, x in enumerate(X):\n",
        "        if args.verbose:\n",
        "            print(f\"Eval sample {i}/{len(X)}\")\n",
        "        pred.append(((model(x) + 1) / 2).to('cpu').detach())\n",
        "    pred = torch.concat(pred)\n",
        "    print(\"Generating output plots...\")\n",
        "    # detach and split images (or parts of images if --n-image-splits is bigger than 1)\n",
        "    imgs = pred.transpose(2, 1).numpy()\n",
        "    imgs = [imgs[i] for i in range(imgs.shape[0])]\n",
        "    if args.wandb is not None:\n",
        "        wandb_pred = [wandb.Image(img.to('cpu').detach().numpy()) for img in imgs]\n",
        "        wandb_ground_truth = [wandb.Image(x.to('cpu').detach().numpy()) for x in X]\n",
        "        wandb_eval_table = wandb.Table(columns=[\"prediction\", \"ground_truth\"], data=zip(wandb_pred, wandb_ground_truth))\n",
        "        wandb.log({\"eval/results\": wandb_eval_table})\n",
        "\n",
        "    num_images = len(imgs)\n",
        "    num_rows, num_cols = factorize_with_smallest_difference(num_images)\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(5 * num_cols, 5))\n",
        "\n",
        "    # Plot each image in its respective subplot\n",
        "    for i in range(num_images):\n",
        "        if num_images > 1:\n",
        "            ax = axes[i]\n",
        "        else:\n",
        "            ax = axes  # Handle the case when there's only one image\n",
        "\n",
        "        ax.imshow(imgs[i])\n",
        "        ax.set_title(f'Image(/part) {i + 1}')\n",
        "\n",
        "    # Adjust layout to prevent overlapping titles and labels\n",
        "    plt.tight_layout()\n",
        "    print(\"Showing plots...\")\n",
        "    plt.show()\n",
        "\n",
        "# in case this code is copied into a notebook\n",
        "if args.wandb is not None:\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "b5vKzXa0G8AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()  # in case a cell crashes, this has to be run\n",
        "wandb.init(\n",
        "    project=\"arxiv_2006.10739\"\n",
        ")"
      ],
      "metadata": {
        "id": "C-EK-at9pdjp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[p for p in model.parameters()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz9fnLbw1sUI",
        "outputId": "22e6886a-d049-4aff-9c8d-0c16ed6f6598"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-3.1232e-02,  2.0275e-02,  3.8709e-02,  ..., -2.6420e-03,\n",
              "          -1.0928e-03,  2.4996e-03],\n",
              "         [-3.9789e-02,  3.5250e-02, -1.5822e-02,  ...,  4.9967e-03,\n",
              "           3.0828e-03, -8.6522e-03],\n",
              "         [ 4.2548e-03,  3.2771e-02, -4.8080e-03,  ...,  2.5962e-03,\n",
              "           3.1051e-03, -5.5589e-03],\n",
              "         ...,\n",
              "         [-4.4885e-02, -3.8984e-02,  2.4464e-02,  ...,  8.9124e-03,\n",
              "           8.9312e-04,  1.9164e-03],\n",
              "         [-1.6779e-02,  3.5946e-02,  7.3660e-02,  ..., -6.3942e-03,\n",
              "          -1.6342e-02, -1.2195e-03],\n",
              "         [-4.4317e-02, -8.3066e-02,  4.1882e-02,  ...,  8.6526e-04,\n",
              "          -5.1351e-04, -4.6171e-05]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0146, -0.0891, -0.0392, -0.1279, -0.1036, -0.0574, -0.0838, -0.0898,\n",
              "         -0.0452, -0.0392, -0.0239, -0.0377, -0.0772, -0.0528, -0.1382, -0.0667,\n",
              "         -0.1094, -0.0753, -0.0994, -0.0869, -0.0388, -0.1323, -0.1174, -0.0301,\n",
              "         -0.0816, -0.0443, -0.0616, -0.0872, -0.0328, -0.0346, -0.1205, -0.0915,\n",
              "         -0.1487, -0.0524, -0.0221, -0.1174, -0.1438, -0.0010, -0.1478,  0.0255,\n",
              "         -0.0744, -0.0565, -0.0092, -0.1174, -0.0010, -0.0141, -0.0178, -0.1001,\n",
              "         -0.0885, -0.0066, -0.0633,  0.0221,  0.0019,  0.0341, -0.1039, -0.1424,\n",
              "         -0.0915, -0.1309,  0.0135,  0.0360,  0.0708, -0.0706, -0.1101, -0.0366],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.1176, -0.1205, -0.0875,  ...,  0.0195,  0.0209, -0.0127],\n",
              "         [-0.0075,  0.0829, -0.0741,  ..., -0.1296, -0.1821,  0.0032],\n",
              "         [-0.0005, -0.4065,  0.0039,  ..., -0.1588,  0.1679,  0.0666],\n",
              "         ...,\n",
              "         [ 0.0199,  0.2176, -0.1526,  ..., -0.3197, -0.0898, -0.3971],\n",
              "         [ 0.1085,  0.1100, -0.0286,  ...,  0.0435, -0.2991, -0.2480],\n",
              "         [ 0.1152,  0.1126,  0.1328,  ..., -0.1009, -0.2068, -0.1548]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0482,  0.0882,  0.1244,  0.1898,  0.2038,  0.0465,  0.1278,  0.2474,\n",
              "         -0.0654, -0.0109,  0.0855,  0.0292, -0.1572,  0.1149,  0.1111,  0.1291,\n",
              "          0.0839,  0.0446,  0.1047,  0.1254,  0.0418,  0.2137,  0.1563, -0.0277,\n",
              "         -0.1080,  0.0943,  0.1110,  0.1416, -0.5020,  0.2426, -0.0530,  0.1453,\n",
              "         -0.1063,  0.0496,  0.1196, -0.0284,  0.0543,  0.2389,  0.0891,  0.0092,\n",
              "          0.1616,  0.0546,  0.1216, -0.0699,  0.1812,  0.0409, -0.0576, -0.0163,\n",
              "          0.0973, -0.1004,  0.2413,  0.0664,  0.1154,  0.1938,  0.0947, -0.1445,\n",
              "         -0.0683,  0.1149,  0.1150,  0.1678,  0.2055,  0.1420,  0.0583,  0.0967],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0821,  0.0186,  0.2366, -0.1012, -0.0287, -0.0505,  0.1208, -0.0263,\n",
              "          -0.1555,  0.0170,  0.2925, -0.0572,  0.0825, -0.1706, -0.0488,  0.0888,\n",
              "          -0.0133,  0.4365,  0.1047, -0.0560,  0.3203,  0.3374,  0.3101, -0.1050,\n",
              "           0.1380,  0.3228,  0.2729, -0.0723,  0.1070,  0.2544,  0.1756,  0.2960,\n",
              "          -0.0908, -0.1702,  0.3533,  0.0368, -0.0629,  0.1117,  0.2327, -0.0402,\n",
              "          -0.0947, -0.1461,  0.3036, -0.1522,  0.2191, -0.0363, -0.2160,  0.1781,\n",
              "           0.2261, -0.0859, -0.0596,  0.2057,  0.0432,  0.3014,  0.1811,  0.1970,\n",
              "           0.0399,  0.4277, -0.0545,  0.2318,  0.3989,  0.2313,  0.2465,  0.2012],\n",
              "         [ 0.0474, -0.0304,  0.2240, -0.1012, -0.0440, -0.0513,  0.1991, -0.0521,\n",
              "          -0.1562,  0.1532,  0.2516,  0.0571,  0.0486, -0.1422, -0.0486,  0.1743,\n",
              "           0.0250,  0.4206,  0.0954,  0.0732,  0.2776,  0.3374,  0.2329, -0.0733,\n",
              "           0.1449,  0.2548,  0.2156, -0.0730,  0.1088,  0.2538,  0.1032,  0.2448,\n",
              "          -0.0812, -0.1768,  0.4805,  0.2116, -0.0581,  0.1733,  0.2744, -0.0491,\n",
              "          -0.0747, -0.1658,  0.3616, -0.1855,  0.3095, -0.0153, -0.1996,  0.2305,\n",
              "           0.2333, -0.0935, -0.0554,  0.1506, -0.0464,  0.3446,  0.1634,  0.1991,\n",
              "          -0.0341,  0.3273, -0.0286,  0.1642,  0.3099,  0.2722,  0.2372,  0.1931],\n",
              "         [-0.1030, -0.0347,  0.3271, -0.0481, -0.0563, -0.0550,  0.1325, -0.0896,\n",
              "          -0.1484,  0.1641,  0.2232,  0.0007,  0.0090, -0.1196, -0.0599,  0.1171,\n",
              "          -0.0614,  0.4450,  0.2112, -0.0265,  0.3608,  0.3241,  0.3147, -0.0088,\n",
              "           0.1877,  0.3443,  0.2307, -0.0425,  0.0791,  0.2171,  0.0902,  0.3156,\n",
              "          -0.0922, -0.1540,  0.4157,  0.1576, -0.0510,  0.2471,  0.2416, -0.0404,\n",
              "          -0.0355, -0.1280,  0.2934, -0.1682,  0.2493, -0.0176, -0.2007,  0.0985,\n",
              "           0.1248, -0.0868,  0.0523,  0.0931, -0.0409,  0.3362,  0.2139,  0.1313,\n",
              "          -0.0151,  0.3351, -0.0633,  0.2422,  0.3413,  0.2477,  0.2615,  0.1815]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1331, -0.1456, -0.2090], device='cuda:0', requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import wandb\n",
        "\n",
        "\n",
        "class FourierLayer(nn.Module):\n",
        "    def __init__(self, n_fourier_features: int, freq_spacing: str = 'logarithmic', fan_in: int = None, no_grad: bool = True):\n",
        "        super().__init__()\n",
        "        self.nff = n_fourier_features\n",
        "        self.fan_in = fan_in\n",
        "        if fan_in is not None:\n",
        "            self.out_dim = 2 * fan_in * self.nff\n",
        "        else:\n",
        "            self.out_dim = None\n",
        "        self.freq_spacing = freq_spacing\n",
        "        self.no_grad = no_grad\n",
        "\n",
        "    def forward_fn(self, x):\n",
        "        x = x.view(x.shape + (1,))\n",
        "        if self.freq_spacing == 'logarithmic':\n",
        "            feature_mul = 2 ** torch.arange(0, self.nff, device=x.device)\n",
        "        elif self.freq_spacing == 'linear':\n",
        "            feature_mul = torch.arange(1, self.nff + 1, device=x.device)\n",
        "        else:\n",
        "            raise Exception(f'Unknown frequency spacing paradigm: {self.freq_spacing}')\n",
        "        sines = torch.sin(x * feature_mul)\n",
        "        cosines = torch.cos(x * feature_mul)\n",
        "        del feature_mul\n",
        "        # sines.shape = cosines.shape\n",
        "        out = (torch.concat([\n",
        "            sines.view(sines.shape + (1,)),\n",
        "            cosines.view(cosines.shape + (1,))\n",
        "        ],\n",
        "            dim=-1)\n",
        "               .flatten(-3, -1)\n",
        "               )\n",
        "        del sines, cosines\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert not (self.no_grad and x.requires_grad), \"FourierLayer is set to no_grad = True, but input requires grad.\"\n",
        "        if self.no_grad:\n",
        "            with torch.no_grad():\n",
        "                return self.forward_fn(x).detach()\n",
        "        return self.forward_fn(x)\n",
        "\n",
        "\n",
        "# todo: add wandb here and test wandb in main\n",
        "\n",
        "\n",
        "def factorize_with_smallest_difference(n):\n",
        "    factors = []\n",
        "\n",
        "    for i in range(1, int(n ** 0.5) + 1):\n",
        "        if n % i == 0:\n",
        "            factors.append((i, n // i))\n",
        "\n",
        "    best_factors = min(factors, key=lambda pair: abs(pair[0] - pair[1]))\n",
        "\n",
        "    return best_factors\n",
        "\n",
        "\n",
        "\"\"\"parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--cuda', action='store_true')\n",
        "parser.add_argument('--n-frames', type=int)\n",
        "parser.add_argument('--wandb', type=str, default=None, help=\"name of wandb project to log this to\")\n",
        "args = parser.parse_args()\"\"\"  # replace with hardcoded namespace because for colab\n",
        "args = argparse.Namespace(\n",
        "    path=\"views\",\n",
        "    cuda=True,\n",
        "    n_frames=10,\n",
        "    wandb=\"arxiv_2006.10739\"\n",
        ")\n",
        "\n",
        "assert not args.cuda or torch.cuda.is_available(), \"Cuda is not available. Make sure you have pytorch installed with cuda or run this file without --cuda to use cpu instead.\"\n",
        "\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "\n",
        "# get the image size (=resolution)\n",
        "json_fn = None\n",
        "for fn in os.listdir(f\"{args.path}/\"):\n",
        "    if fn.endswith('.json'):\n",
        "        assert json_fn is None, \"More than one json file in data directory. Remove all but the necessary one.\"\n",
        "        json_fn = fn\n",
        "\n",
        "assert json_fn is not None, \"Could not find a json file containing dataset info\"\n",
        "\n",
        "with open(f\"{args.path}/{json_fn}\") as f:\n",
        "    data_json = json.load(f)\n",
        "\n",
        "img_path = data_json[0]['image']\n",
        "resolution = (1536, 864)#Image.open(img_path).size\n",
        "\n",
        "grid_in = torch.stack(\n",
        "    [\n",
        "        torch.linspace(-1, 1, resolution[0]).unsqueeze(-1).repeat_interleave(resolution[1], dim=1),\n",
        "        torch.linspace(-1, 1, resolution[1]).unsqueeze(0).repeat_interleave(resolution[0], dim=0)\n",
        "    ],\n",
        "    dim=-1\n",
        ")\n",
        "if args.cuda:\n",
        "    model = model.to('cuda')\n",
        "    grid_in = grid_in.to('cuda')\n",
        "\n",
        "\n",
        "# Empty function for feeding data through the model\n",
        "def predict_view(position, rotation):\n",
        "    model_in = (torch.tensor(position + rotation, dtype=torch.float32)\n",
        "                .view((1, 1, -1))\n",
        "                .repeat_interleave(resolution[0], dim=0)\n",
        "                .repeat_interleave(resolution[1], dim=1))\n",
        "    if args.cuda:\n",
        "        model_in = model_in.to('cuda')\n",
        "    model_in = torch.concat([model_in, grid_in], dim=-1)\n",
        "    model_in = model_in.unsqueeze(0)\n",
        "    model_in = model_in.detach()\n",
        "    model_in.requires_grad = False\n",
        "    model_out = (model(model_in) + 1) / 2\n",
        "    del model_in\n",
        "    out = model_out.squeeze(0).to('cpu').detach().transpose(1, 0).numpy()\n",
        "    del model_out\n",
        "    return out\n",
        "\n",
        "\n",
        "if args.wandb is not None:\n",
        "    wandb.login(anonymous='allow')\n",
        "    wandb.init(\n",
        "        project=args.wandb\n",
        "    )\n",
        "\n",
        "# Parameters for the animation\n",
        "num_frames = args.n_frames\n",
        "radius = 5.0\n",
        "angle_steps = np.linspace(0, 2 * np.pi, num_frames)\n",
        "\n",
        "# Initialize figure and 3D axes\n",
        "num_rows, num_cols = factorize_with_smallest_difference(num_frames)\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5))\n",
        "\n",
        "# List to store frames\n",
        "animation_frames = []\n",
        "\n",
        "# Generate camera positions and rotations\n",
        "camera_positions = [\n",
        "    [radius * np.cos(angle), radius * np.sin(angle), 3.0]\n",
        "    for angle in angle_steps\n",
        "]\n",
        "camera_rotations = [\n",
        "    [0, 0, np.arctan2(-position[1], -position[0])]\n",
        "    for position in camera_positions\n",
        "]\n",
        "\n",
        "wandb_image_table = wandb.Table(columns=[\"frames\"])  # only used if wandb project name was provided using --wandb\n",
        "\n",
        "# Generate images using the model for each camera position and rotation\n",
        "for frame in range(num_frames):\n",
        "    camera_position = camera_positions[frame]\n",
        "    camera_rotation = camera_rotations[frame]\n",
        "\n",
        "    # Feed camera data through the model and get the generated image\n",
        "    generated_image = predict_view(camera_position, camera_rotation)\n",
        "    if args.wandb is not None:\n",
        "        wandb_img = wandb.Image(generated_image)\n",
        "        wandb_image_table.add_row(wandb_img)\n",
        "\n",
        "    # Display the generated image in the respective subplot\n",
        "    if num_frames > 1:\n",
        "        ax = axes[frame // num_cols, frame % num_cols]\n",
        "    else:\n",
        "        ax = axes  # Handle the case when there's only one frame\n",
        "\n",
        "    ax.imshow(generated_image)\n",
        "    ax.set_title(f'Frame {frame + 1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "if args.wandb is not None:\n",
        "    wandb.log({'animation/images': wandb_image_table})\n",
        "    wandb.finish()\n",
        "\n",
        "# Adjust layout to prevent overlapping titles and labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9251dbeeff944d568949047c005828e6",
            "52a87c12157f40f0bb4454dd6cb54a99",
            "74fa73e249a6437a92af6157de21e3ca",
            "7737207cb45f42439bbc105815421bff",
            "66e7379d4d2e46ae9bcbac51dec080b1",
            "1e6681e181104d22abe55ca73bba1c43",
            "4e92733dacf24b3da4c09ceaca1ae329",
            "d2b8f79a46534fb59a55860933ebce8a"
          ]
        },
        "id": "bf_4L2ffh1ZJ",
        "outputId": "dcd73b71-6af1-42b5-8fcf-ef5b6eb77401"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:cmfaoacs) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9251dbeeff944d568949047c005828e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dainty-rain-1</strong> at: <a href='https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739/runs/cmfaoacs?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba' target=\"_blank\">https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739/runs/cmfaoacs?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230827_203342-cmfaoacs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:cmfaoacs). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230827_210749-ley2mqfp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739/runs/ley2mqfp?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba' target=\"_blank\">balmy-durian-2</a></strong> to <a href='https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba' target=\"_blank\">https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739/runs/ley2mqfp?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba' target=\"_blank\">https://wandb.ai/anony-mouse-407731180117466407/arxiv_2006.10739/runs/ley2mqfp?apiKey=e1f45806895e274cbf0e01bf08288c9c13a3b8ba</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-83c14e93ca1f>\u001b[0m in \u001b[0;36m<cell line: 162>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# Feed camera data through the model and get the generated image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_rotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mwandb_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-83c14e93ca1f>\u001b[0m in \u001b[0;36mpredict_view\u001b[0;34m(position, rotation)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mmodel_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mmodel_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-83c14e93ca1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FourierLayer is set to no_grad = True, but input requires grad.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'FourierLayer' object has no attribute 'no_grad'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cmgWrhA9_bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1tv4yuvrSyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}